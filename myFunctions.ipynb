{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMURTLVJx8aLp3NrpKRT8E5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pMABcRVnRUy1"},"outputs":[],"source":["import time\n","\n","# Calcul Tsne, détermination des clusters et calcul ARI entre vrais catégorie et n° de clusters\n","def ARI_fct(features, ) :\n","    time1 = time.time()\n","    num_labels=len(l_cat)\n","    tsne = manifold.TSNE(n_components=2, perplexity=30, n_iter=2000, \n","                                 init='random', learning_rate=200, random_state=42)\n","    X_tsne = tsne.fit_transform(features)\n","    # Détermination des clusters à partir des données après Tsne \n","    cls = cluster.KMeans(n_clusters=num_labels, n_init=100, random_state=42)\n","    cls.fit(X_tsne)\n","    ARI = np.round(metrics.adjusted_rand_score(y_cat_num, cls.labels_),4)\n","    time2 = np.round(time.time() - time1,0)\n","    print(\"ARI : \", ARI, \"time : \", time2)\n","    return ARI, X_tsne, cls.labels_\n","\n","\n","# visualisation du Tsne selon les vraies catégories et selon les clusters\n","def TSNE_visu_fct(X_tsne, y_cat_num, labels, ARI) :\n","    fig = plt.figure(figsize=(15,6))\n","    \n","    ax = fig.add_subplot(121)\n","    scatter = ax.scatter(X_tsne[:,0],X_tsne[:,1], c=y_cat_num, cmap='Set1')\n","    ax.legend(handles=scatter.legend_elements()[0], labels=l_cat, loc=\"best\", title=\"Categorie\")\n","    plt.title('Représentation des tweets par catégories réelles')\n","    \n","    ax = fig.add_subplot(122)\n","    scatter = ax.scatter(X_tsne[:,0],X_tsne[:,1], c=labels, cmap='Set1')\n","    ax.legend(handles=scatter.legend_elements()[0], labels=set(labels), loc=\"best\", title=\"Clusters\")\n","    plt.title('Représentation des tweets par clusters')\n","    \n","    plt.show()\n","    print(\"ARI : \", ARI)\n","\n","\n","def cnn_redimensionner_image(image):\n","    '''\n","    Image à redimensionner en 224*224 en conservant les proportions.\n","    Parameters\n","    ----------\n","    image : image à sauvegarder, obligatoire.\n","    Returns\n","    -------\n","    Répertoire de localisation de l'image redimensionnée.\n","    '''\n","    size = 224, 224\n","    # On charge l'image d'origine\n","    im = Image.open(image)\n","    file_dir = os.path.split(image)\n","    # L'un des côté de l'image fait 224, on garde le ratio original\n","    # (pas de déformation)\n","    im.thumbnail(size, Image.ANTIALIAS)\n","    # On enregistre dans un nouveau dossier l'image redimensionnée.\n","    im.save('data/Images_redim/' + file_dir[1])\n","\n","    # Centrage\n","    im = Image.open('data/Images_redim/' + file_dir[1])\n","    width, height = im.size\n","\n","    if height > width:\n","        img = Image.new('RGB', (224, 224), (255, 255, 255))  # white\n","        position_larg = int((height - width) / 2)\n","        img.paste(im, box=(position_larg, 0))\n","        img.save('data/Images_redim/' + file_dir[1])\n","\n","    elif width > height:\n","        img = Image.new('RGB', (224, 224), (255, 255, 255))  # white\n","        position_haut = int((width - height) / 2)\n","        img.paste(im, box=(0, position_haut))\n","        img.save(\"data/Images_redim/\" + file_dir[1])\n","\n","    return 'data/Images_redim/' + file_dir[1]\n","\n","def tsne_proj(input, data_tf):\n","    tfidf_tsne = TSNE(n_components=2).fit_transform(input)\n","    tfidf_tsne_df = pd.DataFrame(\n","        tfidf_tsne,\n","        columns=['tsne 2D - One', 'tsne 2D - Two'])\n","    tfidf_proj = pd.merge(data_tf,\n","                          tfidf_tsne_df,\n","                          left_index=True,\n","                          right_index=True,\n","                          how='inner')\n","    plt.figure(figsize=(10, 10))\n","    sns.scatterplot(x='tsne 2D - One',\n","                    y='tsne 2D - Two',\n","                    hue='cat_lvl_1',\n","                    palette='Set2',\n","                    data=tfidf_proj)\n","    \n","\n","def topic_table(model, feature_names, n_top_words):\n","    topics = {}\n","    for topic_idx, topic in enumerate(model.components_):\n","        t = (topic_idx)\n","        topics[t] = [feature_names[i] for i in top_words(topic, n_top_words)]\n","    return pd.DataFrame(topics)\n","\n","def topics_tsne_proj(input, data_tf):\n","    model_df = pd.DataFrame(input)\n","    model_df['Best_Topic'] = model_df.idxmax(axis=1)\n","    model_tsne = TSNE(n_components=2).fit_transform(input)\n","    model_tsne_df = pd.DataFrame(\n","        model_tsne,\n","        columns=['tsne 2D - One', 'tsne 2D - Two'])\n","    model_proj = pd.merge(data_tf,\n","                          model_tsne_df,\n","                          left_index=True,\n","                          right_index=True,\n","                          how='inner')\n","    model_proj = pd.merge(model_proj,\n","                          model_df,\n","                          left_index=True,\n","                          right_index=True,\n","                          how='inner')\n","    plt.figure(figsize=(10, 10))\n","    sns.scatterplot(x='tsne 2D - One',\n","                    y='tsne 2D - Two',\n","                    hue='cat_lvl_1',\n","                    style='Best_Topic',\n","                    palette='Set2',\n","                    s=70,\n","                    data=model_proj)\n","\n","# extract features @path\n","def extract_features(img_path, model):\n","\n","    # load image and convert it to grayscale\n","    # img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","\n","    # load image\n","    img = cv2.imread(img_path)\n","    # detect key points and descriptors\n","    keypoints, descriptors = model.detectAndCompute(img, None)\n","\n","    # returns keypoints and descriptors\n","    return keypoints, descriptors\n","\n","def combine_and_cluster(text_features, img_features):\n","    # temp features dataframe\n","    features_to_clust = pd.DataFrame()\n","    # store results\n","    results = pd.DataFrame()\n","    # target to evaluate clustering with ARI\n","    target = data['cat_lvl_1']\n","    # define clusterer\n","    kmeans = KMeans(n_clusters=7)\n","\n","    # loop over combinations\n","    # text as dictionary dim [0] of product, image as dim[1]\n","    for features in itertools.product(text_features, img_features):\n","        if (features[0] != 'None') or (features[1] != 'None'):\n","            if features[0] == 'None':\n","                name_iter = features[1]\n","                features_to_clust = img_features[features[1]]\n","            elif features[1] == 'None':\n","                name_iter = features[0]\n","                features_to_clust = text_features[features[0]]\n","            else:\n","                name_iter = features[0] + '+' + features[1]\n","                features_to_clust = np.concatenate(\n","                    (text_features[features[0]],\n","                     img_features[features[1]]),\n","                    axis=1)\n","            # fit and get labels\n","            kmeans.fit(features_to_clust)\n","            # store result\n","            results.loc[name_iter, 'ARI'] = adjusted_rand_score(\n","                target,\n","                kmeans.labels_)\n","    return results\n","\n","def clusters_tsne_proj(input, labels, data_tf):\n","    data_tf['clusters'] = labels\n","    model_tsne = TSNE(n_components=2).fit_transform(input)\n","    model_tsne_df = pd.DataFrame(\n","        model_tsne,\n","        columns=['tsne 2D - One', 'tsne 2D - Two'])\n","    model_proj = pd.merge(data_tf,\n","                          model_tsne_df,\n","                          left_index=True,\n","                          right_index=True,\n","                          how='inner')\n","    plt.figure(figsize=(10, 10))\n","    sns.scatterplot(x='tsne 2D - One',\n","                    y='tsne 2D - Two',\n","                    hue='cat_lvl_1',\n","                    style='clusters',\n","                    palette='Set2',\n","                    s=70,\n","                    data=model_proj)"]}]}